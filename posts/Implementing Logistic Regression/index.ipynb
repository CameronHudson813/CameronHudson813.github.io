{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: Logistic Regression\n",
    "author: Cameron Hudson\n",
    "date: '2025-04-06'\n",
    "image: \"image.jpg\"\n",
    "description: \"A blog post to implement and discover Logistic Regression\"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from logistic import LogisticRegression, GradientDescentOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link to Source Code\n",
    "[logistic.py](https://github.com/CameronHudson813/CameronHudson813.github.io/blob/main/posts/Implementing%20Perceptron/perceptron.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def classification_data(n_points = 300, noise = 0.2, p_dims = 2):\n",
    "    \n",
    "    y = torch.arange(n_points) >= int(n_points/2)\n",
    "    y = 1.0*y\n",
    "    X = y[:, None] + torch.normal(0.0, noise, size = (n_points,p_dims))\n",
    "    X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X, y = classification_data(noise = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "GradientDescentOptimizer() takes no arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m LR \u001b[38;5;241m=\u001b[39m LogisticRegression() \n\u001b[0;32m----> 2\u001b[0m opt \u001b[38;5;241m=\u001b[39m \u001b[43mGradientDescentOptimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# add other stuff to e.g. keep track of the loss over time. \u001b[39;00m\n\u001b[1;32m      6\u001b[0m     opt\u001b[38;5;241m.\u001b[39mstep(X, y, alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m, beta \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.9\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: GradientDescentOptimizer() takes no arguments"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression() \n",
    "opt = GradientDescentOptimizer(LR)\n",
    "\n",
    "for _ in range(100):\n",
    "    # add other stuff to e.g. keep track of the loss over time. \n",
    "    opt.step(X, y, alpha = 0.1, beta = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-0451",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
