<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Cameron Hudson">
<meta name="dcterms.date" content="2025-04-16">
<meta name="description" content="Discussion of the efficacy of quantitative methods in evaluating the fairness of machine learning algorithms.">

<title>Limits of the Quantitative Approach to Bias and Fairness – My Awesome CSCI 0451 Blog</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-6de787833effe4777a6777a5e05fb578.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>

      .quarto-title-block .quarto-title-banner h1,
      .quarto-title-block .quarto-title-banner h2,
      .quarto-title-block .quarto-title-banner h3,
      .quarto-title-block .quarto-title-banner h4,
      .quarto-title-block .quarto-title-banner h5,
      .quarto-title-block .quarto-title-banner h6
      {
        color: white;
      }

      .quarto-title-block .quarto-title-banner {
        color: white;
background-image: url(../../img/landscape.png);
background-size: cover;
      }
</style>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">My Awesome CSCI 0451 Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">Cameron Hudson’s Machine Learning Blog</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Limits of the Quantitative Approach to Bias and Fairness</h1>
                  <div>
        <div class="description">
          Discussion of the efficacy of quantitative methods in evaluating the fairness of machine learning algorithms.
        </div>
      </div>
                </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Cameron Hudson </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">April 16, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="abstract" class="level1">
<h1>Abstract</h1>
<p>This post explores the benefits and drawbacks of using quantitative methods to measure and detect discrimination. Quantitative approaches rely on mathematical definitions, machine learning algorithm auditing, and statistical tests to identify biases. However, <span class="citation" data-cites="narayanan2022limits">Narayanan (<a href="#ref-narayanan2022limits" role="doc-biblioref">2022</a>)</span> argues these methods often fail to capture the complexity of discrimination, leading to misleading conclusions and reinforcing existing inequalities. This post will examine Narayanan’s critique while also acknowledging cases where quantitative analysis has effectively exposed bias.</p>
</section>
<section id="narayanans-position" class="level1">
<h1>Narayanan’s Position</h1>
<p>Narayanan argues that quantitative methods are fundamentally inadequate for studying and addressing discrimination, as they often reinforce the status quo, which in turn leads to inaction due to the failure of the methods to detect discrimination. He begins his critique by highlighting a stark reality: “about 1% of Fortune 500 CEOs are Black” (<span class="citation" data-cites="narayanan2022limits">Narayanan (<a href="#ref-narayanan2022limits" role="doc-biblioref">2022</a>)</span>). Despite clear evidence of racial discrimination in the United States, the prevailing assumption—what Narayanan calls the “null hypothesis”—is that discrimination does not exist. This assumption shifts the burden of proof onto those who argue that racial disparities, such as the low number of Black Fortune 500 CEOs, are the result of systemic discrimination.</p>
<p>Narayanan further critiques quantitative methods by introducing the concept of compound inequality. He illustrates that even a seemingly small bias—such as a 2.5% advantage for white employees in quarterly performance reviews—can accumulate over time, leading to significant disparities in leadership representation. Crucially, he argues that such subtle, yet impactful biases are often undetectable by quantitative analysis, rendering these methods ineffective at uncovering the true extent of discrimination. Such an issue of incremental, long lasting discrimination being undetectable by quantitative methods is also addressed by Narayanan’s criticism of the data that is often used by quantitative methods themselves. Narayanan asserts that most datasets are snapshots, measurements of phenomenon in discrete and short points of time. Thus, it is incredibly difficult for these quantitative methods to capture discrimination, which is often incremental and persists for long periods of time.</p>
<p>Moreover, Narayanan argues that those in power can manipulate or selectively present data to misrepresent marginalized groups and reinforce false narratives. Narayanan also points out, such as the case of performance review bias in Fortune 500 companies, relevant data is excluded or extremely difficult to include in datasets, challenging the idea the discrimination can be measured in discrete quantitative snapshots and not through imperceivable events throughout the course of a person’s lifetime. It is with these points that Narayanan asserts that quantitative methods, being poor at detecting man forms of discrimination, are being utilized to report a lack of discrimination where there actually is discrimination, and thus feels that quantitative methods are doing more harm than good.</p>
</section>
<section id="benefits-of-quantitative-methods" class="level1">
<h1>Benefits of Quantitative Methods</h1>
<p>Despite Narayanan’s criticisms, quantitative methods have played an essential role in uncovering systemic discrimination in machine learning algorithms. They excel in cases where disparities can be objectively measured. One notable example is ProPublica’s use of quantitative methods to reveal racial bias in Northpointe’s recidivism risk assessment algorithm (<span class="citation" data-cites="angwin2022machine">Angwin et al. (<a href="#ref-angwin2022machine" role="doc-biblioref">2022</a>)</span>). Northpointe’s algorithm assigned risk scores to offenders, predicting their likelihood of reoffending. ProPublica’s audit revealed several critical flaws. The algorithm’s positive predictive value was alarmingly low, with only 20% of those predicted to commit violent crimes actually doing so. Furthermore, the algorithm failed the error rate parity fairness criterion: Black defendants had significantly higher false positive rates (wrongly classified as high risk), while white defendants had disproportionately high false negative rates (wrongly classified as low risk). The audit demonstrated that not only was the algorithm a poor predictor of recidivism, but it also exhibited significant racial bias against Black defendants. Through quantitative analysis, ProPublica exposed how the algorithm generalized and prejudiced individuals based on race. For instance, it reported cases where white defendants with extensive criminal histories received lower risk scores than Black defendants with no prior arrests. By shifting the burden of proof onto Northpointe, quantitative methods played a key role in prompting a broader investigation into the moral implications of using flawed and biased algorithms in judicial decision-making.</p>
<section id="limitations-of-quantitative-methods" class="level2">
<h2 class="anchored" data-anchor-id="limitations-of-quantitative-methods">Limitations of Quantitative Methods</h2>
<p>Other scholars including Narayanan report the various limitations of quantitative methods in detecting discrimination. Narayanan, in his speech, specifically refers to ProPublica as being the cause of his disillusionment with the usefulness of quantitative methods. Narayanan expounds on his viewpoint referring to the developers of the COMPAS RPI in the quote, “If the developers of risk prediction algorithms redesigned them to equalize the rates of falsely flagging someone as high risk, between Black defendants and white defendants, that doesn’t solve the problem. It remains profoundly unjust to deny someone their freedom based on a prediction that they might commit another crime or a prediction that they might not appear in court for their arraignment or their trial”(<span class="citation" data-cites="narayanan2022limits">Narayanan (<a href="#ref-narayanan2022limits" role="doc-biblioref">2022</a>)</span>). The dilemma which Narayanan describes can be explained through description of the differences between the “broad view” and the “middle view” in <span class="citation" data-cites="barocasFairnessMachineLearning2023">Barocas, Hardt, and Narayanan (<a href="#ref-barocasFairnessMachineLearning2023" role="doc-biblioref">2023</a>)</span>. What Narayanan describes equalizing error rates would align with is be the “middle view”: the equalization of error rates in RPI’s and discriminatory systems refers to an enforcement of fairness at the decision-making level. What Narayanan believes is right, however, is more in line with the “broad view”. The broad view states that fairness should be addressed at the systemic level, and that the racial biases of RPI’s are a symptom of a larger problem. Through the example of ProPublica’s COMPAS audit, Narayanan demonstrates that even when quantitative methods can reveal injustice, they often do not provide the means or solutions to the root cause of those injustices. Within chouldechova2017fair,ProPublica’s COMPAS audit is also criticized on its choice of fairness criteria, demonstrated in the quote, “Flores et al.&nbsp;[6] argue that the correct approach for assessing RPI bias is instead to check for calibration, a fairness criterion that they show COMPAS satisfies. Northpointe in their response[7] argue for a still different approach that checks for a fairness criterion termed predictive parity, which they demonstrate COMPAS also satisfies” (chouldechova2017fair). Chouldechova continues in his paper to prove algebraically that when prevalence differs among groups, the fairness criterions error rate parity and predictive parity can be satisfied simultaneously. The mathematical proof and reported push back of ProPublica’s audit in Chouldechova’s paper illustrate how quantitative methods can be insufficient in detecting real group bias as decision making systems can fulfill certain fairness criterion and not others. Other scholars report that the limits of quantiative methods lie in their reliance on incomplete or missing data. <span class="citation" data-cites="d2023data">D’ignazio and Klein (<a href="#ref-d2023data" role="doc-biblioref">2023</a>)</span> highlight how Black women in the United States suffer disproportionately high maternal mortality rates. Yet, when researchers sought to investigate this disparity, they found a shocking reality—no reliable datasets existed to confirm or study the problem. As D’Ignazio and Klein note, “Nobody was counting.” A 2014 United Nations report described maternal mortality data collection in the United States as “particularly weak.” This example underscores a critical issue: quantitative methods become ineffective when the necessary data does not exist. The lack of relevant data often stems from the demographics of those responsible for collecting and analyzing it. D’Ignazio and Klein highlight that, as of 2018, only 26% of professionals in “computer and mathematical operations” were women, and only 12% of those were Black or Latinx women, despite these groups comprising 22.5% of the U.S. population.</p>
<p>This demographic imbalance creates a privilege hazard, where those in positions of power and influence—who are not personally affected by systemic discrimination—fail to recognize its existence, leading to the invisibility of marginalized experiences in data collection. Other scholars further critique the assumption that fairness can be adequately measured through mathematical models. The fairness of a machine learning system extends beyond technical accuracy and error rate parity; it also involves broader social and epistemological concerns. As one study points out, “The fairness of a data science project extends far beyond the technical properties of a given model and includes normative and epistemological issues that arise during processes of problem formulation, data collection, and real-world application.” In other words, quantitative metrics alone cannot account for the deeper structural inequalities that exist before any algorithm is even built. <span class="citation" data-cites="hardtPatternsPredictionsActions2022">Hardt and Recht (<a href="#ref-hardtPatternsPredictionsActions2022" role="doc-biblioref">2022</a>)</span> encapsulate this critique by arguing that discriminatory design does not require intentional malice. As he explains, “One need not harbor any racial animus to exercise racism… rather, when the default settings have been stipulated, simply doing one’s job…is enough to ensure the consistency of white domination over time.” This highlights how data-driven decision-making often reinforces existing social hierarchies, even in the absence of explicit bias.</p>
<p>This idea is further emphasized by <span class="citation" data-cites="eubanks2018digital">Eubanks (<a href="#ref-eubanks2018digital" role="doc-biblioref">2018</a>)</span>, who discusses in her article how automated systems are designed to perpetuate inequality and increase the ethical distance between human decision-makers, thereby justifying systemic bias. The article introduces the term “rational discrimination,” which serves as the justification and backbone of biased algorithms. Eubanks states, “Rational discrimination does not require class or racial hatred, or even unconscious bias, to operate. It requires only ignoring bias that already exists.” This aligns with the argument that data collection itself is a central issue in fairness for machine learning algorithms—one that cannot be addressed merely by measuring algorithmic outcomes across different groups. If the data does not accurately reflect the reality of discrimination or contains inherent biases, then no amount of technical auditing can uncover the deeper inequities that were embedded long before the algorithm was even created. This notion of “rational discrimination” aligns with Narayanan’s critique of quantitative methods, which he argues often serve to justify the status quo rather than challenge it.</p>
<p>In a fundamentally discriminatory system, rational discrimination operates within what <span class="citation" data-cites="barocasFairnessMachineLearning2023">Barocas, Hardt, and Narayanan (<a href="#ref-barocasFairnessMachineLearning2023" role="doc-biblioref">2023</a>)</span> refer to as the “narrow view.” The narrow view asserts that people who are similar with respect to a task should be given similar opportunities and rewards, evaluating fairness purely at the level of the individual without considering how systemic discrimination shapes opportunities in the first place. This framework falsely presents itself as “meritorious” and “fair,” despite statistical realities suggesting otherwise—such as Narayanan’s observation that only 1% of Fortune 500 CEOs are Black. What rational discrimination fails to consider are the perspectives captured in the “middle view” and “broad view,” which acknowledge historical oppression and advocate for interventions that challenge systemic inequality. These perspectives call for active efforts to remedy disparities rather than passively accepting them as natural outcomes of a supposedly neutral process. However, such interventions are often absent from quantitative methods, as these issues extend beyond what numerical evaluations alone can address. As Narayanan explains, quantitative analyses frequently produce superficially plausible explanations that discourage further investigation or action. This is evident in his critique of the Fortune 500 CEO statistic: “As a quantitative scholar, you’re not allowed to conclude from this that there is discrimination in Fortune 500 companies. You’re supposed to be open to all possibilities. Like maybe Black people just aren’t that interested in becoming CEOs (<span class="citation" data-cites="narayanan2022limits">Narayanan (<a href="#ref-narayanan2022limits" role="doc-biblioref">2022</a>)</span>).” This is just one example of how quantitative methods, when used in isolation, fail to meaningfully challenge discrimination. By allowing for convenient yet flawed interpretations, these methods risk reinforcing existing disparities rather than prompting meaningful change.</p>
</section>
</section>
<section id="my-point-of-view" class="level1">
<h1>My Point of View</h1>
<p>I agree with Narayanan’s assertion that quantitative methods are inherently limiting and often serve to deflect accusations of discrimination rather than substantiate them. While cases like ProPublica’s audit of Northpointe’s algorithm demonstrate that quantitative analysis can expose algorithmic bias, these methods become far less effective when oppressive structures manipulate data or when discrimination operates in ways that are not easily quantifiable.</p>
<p>Quantitative approaches struggle with missing data, privileged perspectives in data collection, and the long-term accumulation of subtle biases. Furthermore, these methods are frequently used to absolve institutions of responsibility by maintaining the “null hypothesis” that discrimination does not exist unless proven with statistical certainty. This ignores the lived experiences of marginalized groups and the broader socio-political forces that shape inequality.</p>
<p>While quantitative methods should not be abandoned entirely, they must be supplemented with qualitative research, historical context, and critical perspectives that account for the limitations of data-driven approaches. Discrimination cannot be reduced to a set of statistical tests; rather, it must be understood as a complex, systemic issue that requires a broader analytical lens.</p>
<p>References <span class="citation" data-cites="barocasFairnessMachineLearning2023">Barocas, Hardt, and Narayanan (<a href="#ref-barocasFairnessMachineLearning2023" role="doc-biblioref">2023</a>)</span> <span class="citation" data-cites="narayanan2022limits">Narayanan (<a href="#ref-narayanan2022limits" role="doc-biblioref">2022</a>)</span> <span class="citation" data-cites="hardtPatternsPredictionsActions2022">Hardt and Recht (<a href="#ref-hardtPatternsPredictionsActions2022" role="doc-biblioref">2022</a>)</span> <span class="citation" data-cites="eubanks2018digital">Eubanks (<a href="#ref-eubanks2018digital" role="doc-biblioref">2018</a>)</span> <span class="citation" data-cites="angwin2022machine">Angwin et al. (<a href="#ref-angwin2022machine" role="doc-biblioref">2022</a>)</span> <span class="citation" data-cites="d2023data">D’ignazio and Klein (<a href="#ref-d2023data" role="doc-biblioref">2023</a>)</span> <span class="citation" data-cites="chouldechova2017fair">Chouldechova (<a href="#ref-chouldechova2017fair" role="doc-biblioref">2017</a>)</span></p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-angwin2022machine" class="csl-entry" role="listitem">
Angwin, Julia, Jeff Larson, Surya Mattu, and Lauren Kirchner. 2022. <span>“Machine Bias.”</span> In <em>Ethics of Data and Analytics</em>, 254–64. Auerbach Publications.
</div>
<div id="ref-barocasFairnessMachineLearning2023" class="csl-entry" role="listitem">
Barocas, Solon, Moritz Hardt, and Arvind Narayanan. 2023. <em>Fairness and Machine Learning: Limitations and Opportunities</em>. <span>Cambridge, Massachusetts</span>: <span>The MIT Press</span>.
</div>
<div id="ref-chouldechova2017fair" class="csl-entry" role="listitem">
Chouldechova, Alexandra. 2017. <span>“Fair Prediction with Disparate Impact: A Study of Bias in Recidivism Prediction Instruments.”</span> <em>Big Data</em> 5 (2): 153–63.
</div>
<div id="ref-d2023data" class="csl-entry" role="listitem">
D’ignazio, Catherine, and Lauren F Klein. 2023. <em>Data Feminism</em>. MIT press.
</div>
<div id="ref-eubanks2018digital" class="csl-entry" role="listitem">
Eubanks, Virginia. 2018. <span>“The Digital Poorhouse.”</span> <em>Harper’s Magazine</em>.
</div>
<div id="ref-hardtPatternsPredictionsActions2022" class="csl-entry" role="listitem">
Hardt, Moritz, and Benjamin Recht. 2022. <em>Patterns, <span>Predictions</span>, and <span>Actions</span></em>. <span>Princeton University Press</span>.
</div>
<div id="ref-narayanan2022limits" class="csl-entry" role="listitem">
Narayanan, Arvind. 2022. <span>“The Limits of the Quantitative Approach to Discrimination.”</span> Speech.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>