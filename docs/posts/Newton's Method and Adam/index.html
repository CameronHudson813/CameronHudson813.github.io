<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Cameron Hudson">
<meta name="dcterms.date" content="2025-05-12">
<meta name="description" content="A blog post exploring Newton’s Method of optimizing the logistic regression algorithm">

<title>Newtons’s Method and Adam – My Awesome CSCI 0451 Blog</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-6de787833effe4777a6777a5e05fb578.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>

      .quarto-title-block .quarto-title-banner h1,
      .quarto-title-block .quarto-title-banner h2,
      .quarto-title-block .quarto-title-banner h3,
      .quarto-title-block .quarto-title-banner h4,
      .quarto-title-block .quarto-title-banner h5,
      .quarto-title-block .quarto-title-banner h6
      {
        color: white;
      }

      .quarto-title-block .quarto-title-banner {
        color: white;
background-image: url(../../img/landscape.png);
background-size: cover;
      }
</style>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">My Awesome CSCI 0451 Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">Cameron Hudson’s Machine Learning Blog</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Newtons’s Method and Adam</h1>
                  <div>
        <div class="description">
          A blog post exploring Newton’s Method of optimizing the logistic regression algorithm
        </div>
      </div>
                </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Cameron Hudson </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">May 12, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="abstract" class="level1">
<h1>Abstract</h1>
<div id="cell-2" class="cell" data-execution_count="57">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>load_ext autoreload</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>autoreload <span class="dv">2</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> logisticNewtonAdam <span class="im">import</span> LogisticRegression, GradientDescentOptimizer, NewtonOptimizer, AdamOptimizer</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The autoreload extension is already loaded. To reload it, use:
  %reload_ext autoreload</code></pre>
</div>
</div>
</section>
<section id="newtons-method" class="level1">
<h1>Newton’s Method</h1>
</section>
<section id="testing-newton-method-implementation" class="level1">
<h1>Testing Newton Method Implementation</h1>
<p>In order to test the correctness of the Newton’s Method implementation, I will demonstrate for a sufficiently small learning rate <code>α</code>, Newton’s Method coverges to the same result that regular gradient descent would achieve.</p>
</section>
<section id="generating-classification-data" class="level1">
<h1>Generating Classification Data</h1>
<p>To test Newton’s Method optimization against standard gradient descent, we will generate a 2d set of binary classification data with the <code>generate_classification_data</code> function below.</p>
<div id="cell-6" class="cell" data-execution_count="139">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_classification_data(n_points <span class="op">=</span> <span class="dv">300</span>, noise <span class="op">=</span> <span class="fl">0.5</span>, p_dims <span class="op">=</span> <span class="dv">2</span>):</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> torch.arange(n_points) <span class="op">&gt;=</span> <span class="bu">int</span>(n_points<span class="op">/</span><span class="dv">2</span>)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> <span class="fl">1.0</span><span class="op">*</span>y</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> y[:, <span class="va">None</span>] <span class="op">+</span> torch.normal(<span class="fl">0.0</span>, noise, size <span class="op">=</span> (n_points,p_dims))</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> torch.cat((X, torch.ones((X.shape[<span class="dv">0</span>], <span class="dv">1</span>))), <span class="dv">1</span>)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> X, y</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> generate_classification_data(noise <span class="op">=</span> <span class="fl">0.5</span>)</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"X: </span><span class="sc">{</span>X<span class="sc">}</span><span class="ch">\n</span><span class="ss">y: </span><span class="sc">{</span>y<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>X: tensor([[ 0.1331, -0.5069,  1.0000],
        [ 0.4187,  0.5261,  1.0000],
        [-0.2983,  0.6095,  1.0000],
        [-0.2762, -0.2033,  1.0000],
        [-0.2627,  0.2448,  1.0000],
        [-0.2522,  0.0076,  1.0000],
        [ 0.2728, -0.3588,  1.0000],
        [-0.4089,  0.1683,  1.0000],
        [-0.6963, -0.0694,  1.0000],
        [-0.2051,  0.4304,  1.0000],
        [ 0.1909, -0.8464,  1.0000],
        [ 0.1166,  0.1731,  1.0000],
        [ 1.1864,  0.5177,  1.0000],
        [ 0.3620, -0.3833,  1.0000],
        [-0.6120, -0.4335,  1.0000],
        [-0.0809,  0.8607,  1.0000],
        [-0.5815,  0.1353,  1.0000],
        [ 0.3168, -1.1318,  1.0000],
        [ 0.1718,  0.3886,  1.0000],
        [-0.3228, -0.1408,  1.0000],
        [-0.5979,  0.0414,  1.0000],
        [-0.6130,  0.2337,  1.0000],
        [ 0.2476,  0.1517,  1.0000],
        [-0.6775,  0.0802,  1.0000],
        [-0.4850, -0.1069,  1.0000],
        [ 0.1449,  0.6849,  1.0000],
        [-0.3816,  0.0954,  1.0000],
        [-0.5543,  0.3167,  1.0000],
        [-0.4704,  0.3809,  1.0000],
        [-0.8565,  0.4425,  1.0000],
        [ 0.5731,  1.0433,  1.0000],
        [-0.3849, -0.3297,  1.0000],
        [-0.6868, -0.2638,  1.0000],
        [ 0.9089,  0.0201,  1.0000],
        [-0.3176,  0.4226,  1.0000],
        [-0.3757, -0.3174,  1.0000],
        [-0.5904,  1.4370,  1.0000],
        [ 0.7336, -0.5904,  1.0000],
        [ 0.0961, -0.7408,  1.0000],
        [ 0.2325,  0.0639,  1.0000],
        [-0.3776,  0.6925,  1.0000],
        [ 0.6023,  0.2660,  1.0000],
        [ 0.4420,  0.3346,  1.0000],
        [ 0.5956,  0.3301,  1.0000],
        [ 0.4462, -0.4129,  1.0000],
        [-0.2313, -0.9358,  1.0000],
        [-0.7569, -0.3956,  1.0000],
        [ 0.6142, -0.3605,  1.0000],
        [ 0.3152, -0.2747,  1.0000],
        [ 0.0900, -0.8234,  1.0000],
        [-0.0134, -0.1598,  1.0000],
        [ 0.5709, -0.4076,  1.0000],
        [ 0.2715,  0.5630,  1.0000],
        [-0.2375,  0.2559,  1.0000],
        [ 1.1023, -0.2924,  1.0000],
        [-0.6134, -0.3280,  1.0000],
        [-0.2934, -0.0305,  1.0000],
        [ 0.4149, -0.0807,  1.0000],
        [-0.7792, -0.1801,  1.0000],
        [-0.5370, -0.1105,  1.0000],
        [-0.7524, -0.0264,  1.0000],
        [ 0.0451, -0.8745,  1.0000],
        [-0.1563, -1.3893,  1.0000],
        [ 0.6538, -0.6754,  1.0000],
        [-0.6332, -0.9790,  1.0000],
        [ 0.6932,  0.3684,  1.0000],
        [ 0.1792, -0.5157,  1.0000],
        [ 0.0873, -0.8205,  1.0000],
        [-0.1817,  0.4487,  1.0000],
        [-0.0073, -0.1147,  1.0000],
        [ 1.5882, -0.3857,  1.0000],
        [-0.6397,  0.2955,  1.0000],
        [-0.0893,  0.1900,  1.0000],
        [-0.9487, -0.0137,  1.0000],
        [ 0.1760,  0.7914,  1.0000],
        [ 0.0945,  0.7796,  1.0000],
        [-0.0870,  0.6618,  1.0000],
        [ 0.3157,  0.4296,  1.0000],
        [ 0.2550,  0.7858,  1.0000],
        [ 0.5720, -0.3460,  1.0000],
        [ 0.0374, -0.4952,  1.0000],
        [-0.1146, -0.2138,  1.0000],
        [-0.1414,  0.7533,  1.0000],
        [-0.0163,  0.4258,  1.0000],
        [ 0.2751,  0.6873,  1.0000],
        [-0.7556,  0.0736,  1.0000],
        [ 0.2972,  0.0867,  1.0000],
        [ 0.2202,  0.7592,  1.0000],
        [-0.4357,  0.3405,  1.0000],
        [ 0.1502, -1.2351,  1.0000],
        [ 0.6420,  0.1932,  1.0000],
        [-0.3471,  0.1838,  1.0000],
        [-0.7134, -0.0053,  1.0000],
        [-0.1433,  0.0474,  1.0000],
        [ 0.2392,  0.1363,  1.0000],
        [-0.4311, -0.7110,  1.0000],
        [ 0.2851, -0.4659,  1.0000],
        [ 0.0043, -0.1131,  1.0000],
        [ 0.3214, -0.8073,  1.0000],
        [-0.2994,  0.6678,  1.0000],
        [-0.7217, -0.4693,  1.0000],
        [ 0.2342, -0.4415,  1.0000],
        [-0.1569,  0.8284,  1.0000],
        [-0.0766, -0.7148,  1.0000],
        [ 0.1786,  0.6318,  1.0000],
        [-0.4376,  0.4944,  1.0000],
        [-0.2162, -0.1633,  1.0000],
        [ 0.1791, -0.2712,  1.0000],
        [ 0.3576, -0.3156,  1.0000],
        [-0.4294,  0.4654,  1.0000],
        [ 0.2909, -0.4373,  1.0000],
        [ 0.1757, -0.0087,  1.0000],
        [ 0.3738,  0.1028,  1.0000],
        [-0.3560,  0.5449,  1.0000],
        [ 0.9295, -0.0075,  1.0000],
        [-0.4331, -0.2177,  1.0000],
        [ 0.5616,  0.4446,  1.0000],
        [-0.1917,  0.0384,  1.0000],
        [-0.0284,  0.6887,  1.0000],
        [ 0.2411,  0.9062,  1.0000],
        [-0.0545, -0.1652,  1.0000],
        [ 0.5673, -0.7436,  1.0000],
        [-0.4248,  0.1280,  1.0000],
        [-0.7716,  0.1606,  1.0000],
        [ 0.7165,  0.4007,  1.0000],
        [-0.3119, -0.9163,  1.0000],
        [-0.0244,  0.0823,  1.0000],
        [ 0.2067, -0.1202,  1.0000],
        [-0.1462, -0.1338,  1.0000],
        [-0.1623, -0.2097,  1.0000],
        [-0.3307,  1.0402,  1.0000],
        [-0.3396,  0.4297,  1.0000],
        [-0.6635,  0.4795,  1.0000],
        [ 0.0596,  0.1857,  1.0000],
        [-0.4363, -0.3012,  1.0000],
        [ 1.1137,  0.1399,  1.0000],
        [ 0.3807,  0.0956,  1.0000],
        [-0.3899,  0.0183,  1.0000],
        [ 0.5573,  0.7184,  1.0000],
        [-0.4150,  0.5053,  1.0000],
        [ 0.7424,  0.2786,  1.0000],
        [ 0.5013, -0.1183,  1.0000],
        [ 0.6451,  0.5157,  1.0000],
        [ 0.3827,  0.2200,  1.0000],
        [-0.4923, -0.1419,  1.0000],
        [ 0.1584, -0.0343,  1.0000],
        [-1.0731,  0.6030,  1.0000],
        [ 0.5403,  0.0130,  1.0000],
        [-0.0551,  0.1550,  1.0000],
        [-0.6985, -0.7240,  1.0000],
        [ 1.4655,  0.9105,  1.0000],
        [ 1.2500,  0.7366,  1.0000],
        [ 1.4411,  0.7039,  1.0000],
        [ 1.6027,  0.5539,  1.0000],
        [ 0.6114,  1.6419,  1.0000],
        [ 1.5508,  1.6272,  1.0000],
        [ 0.3305,  0.4246,  1.0000],
        [ 1.2746,  1.0889,  1.0000],
        [ 0.8156,  1.0837,  1.0000],
        [ 0.1200,  0.1342,  1.0000],
        [ 0.0287,  0.5136,  1.0000],
        [ 1.9395,  0.9310,  1.0000],
        [ 0.8554,  0.9583,  1.0000],
        [ 1.4490,  1.2197,  1.0000],
        [ 1.4110,  0.6502,  1.0000],
        [ 0.7046,  0.2482,  1.0000],
        [ 0.3969,  0.4183,  1.0000],
        [-0.2829,  0.3144,  1.0000],
        [ 1.3182,  1.2545,  1.0000],
        [ 1.2874,  0.7710,  1.0000],
        [ 1.2861,  0.2561,  1.0000],
        [ 0.5372,  0.8359,  1.0000],
        [ 1.4012,  1.5290,  1.0000],
        [ 1.3349,  0.6617,  1.0000],
        [ 1.6467,  1.2833,  1.0000],
        [ 1.4452,  1.0106,  1.0000],
        [ 0.9027,  1.0919,  1.0000],
        [ 0.3928,  0.9408,  1.0000],
        [ 0.6143,  1.3941,  1.0000],
        [ 1.4518,  0.7951,  1.0000],
        [ 0.8818,  2.1596,  1.0000],
        [ 0.8676,  1.7272,  1.0000],
        [ 0.2290,  1.6438,  1.0000],
        [ 0.7504,  1.1772,  1.0000],
        [ 0.5980,  1.7835,  1.0000],
        [ 1.2934,  1.8412,  1.0000],
        [ 0.3258,  1.2439,  1.0000],
        [ 0.5989,  1.1149,  1.0000],
        [ 0.6206,  1.4095,  1.0000],
        [ 0.8444,  1.3255,  1.0000],
        [ 0.8805, -0.0651,  1.0000],
        [ 0.7978,  0.6888,  1.0000],
        [ 0.7775,  1.6379,  1.0000],
        [ 0.3940,  0.4579,  1.0000],
        [ 0.8396,  1.3161,  1.0000],
        [ 1.3997,  0.8481,  1.0000],
        [ 0.7352,  1.1827,  1.0000],
        [ 1.5696,  1.0127,  1.0000],
        [ 1.5824,  1.8071,  1.0000],
        [-0.1278,  1.4597,  1.0000],
        [ 0.6322,  0.9226,  1.0000],
        [ 1.1156,  1.2813,  1.0000],
        [ 1.5029,  1.4662,  1.0000],
        [ 0.1822,  1.8539,  1.0000],
        [ 0.6391,  0.8902,  1.0000],
        [ 0.9805,  0.5015,  1.0000],
        [ 1.2222,  1.8250,  1.0000],
        [ 1.7340,  1.0449,  1.0000],
        [ 1.2185,  0.0194,  1.0000],
        [ 1.8217,  1.8037,  1.0000],
        [ 0.1951,  1.2689,  1.0000],
        [ 0.7735,  0.8496,  1.0000],
        [ 0.7627,  1.1087,  1.0000],
        [ 1.3059,  1.3112,  1.0000],
        [ 1.5326,  0.6580,  1.0000],
        [ 0.5037,  1.1462,  1.0000],
        [ 1.8760,  1.7601,  1.0000],
        [ 0.7737,  1.1377,  1.0000],
        [ 0.2740,  0.8976,  1.0000],
        [ 0.1951,  1.4352,  1.0000],
        [ 1.1774,  1.5710,  1.0000],
        [ 0.3396,  0.8168,  1.0000],
        [ 0.5737,  1.5381,  1.0000],
        [ 1.0562,  1.5395,  1.0000],
        [ 0.3118,  0.8448,  1.0000],
        [ 0.9814,  0.2286,  1.0000],
        [ 1.7905,  1.3631,  1.0000],
        [ 0.8023,  1.6082,  1.0000],
        [ 0.3342,  0.6692,  1.0000],
        [ 0.7624,  1.0886,  1.0000],
        [ 1.7471,  1.3891,  1.0000],
        [-0.0781,  1.6497,  1.0000],
        [ 0.0130,  1.0696,  1.0000],
        [ 0.6669, -0.0238,  1.0000],
        [ 1.3222,  0.9816,  1.0000],
        [ 1.0281,  0.7035,  1.0000],
        [ 1.4878,  1.9413,  1.0000],
        [ 0.8784,  1.5134,  1.0000],
        [ 0.6387, -0.0455,  1.0000],
        [ 1.2730,  1.0329,  1.0000],
        [ 1.1087,  1.3316,  1.0000],
        [ 0.1826,  0.8805,  1.0000],
        [ 0.5362,  0.8868,  1.0000],
        [ 0.2402,  0.1722,  1.0000],
        [ 0.0703,  0.8987,  1.0000],
        [ 1.1769,  1.3797,  1.0000],
        [ 0.3588,  0.7141,  1.0000],
        [ 1.0876,  1.4334,  1.0000],
        [ 1.7543,  1.5279,  1.0000],
        [ 0.6718,  0.9518,  1.0000],
        [ 0.8398, -0.5626,  1.0000],
        [ 1.6565,  0.7431,  1.0000],
        [ 1.3444,  0.3799,  1.0000],
        [ 1.0211,  0.3876,  1.0000],
        [ 1.2114,  1.2562,  1.0000],
        [ 0.9544,  1.2431,  1.0000],
        [ 1.1240,  0.4235,  1.0000],
        [ 0.5480,  0.3698,  1.0000],
        [ 1.3353,  2.0958,  1.0000],
        [ 0.3898,  0.7619,  1.0000],
        [ 1.1014,  1.3832,  1.0000],
        [ 0.7995,  1.5304,  1.0000],
        [ 1.3529,  0.4032,  1.0000],
        [ 1.6737,  0.4025,  1.0000],
        [ 0.7205,  1.0458,  1.0000],
        [ 0.5732,  1.1179,  1.0000],
        [ 0.5853,  1.5670,  1.0000],
        [ 1.4854,  0.6220,  1.0000],
        [ 0.3671,  1.3274,  1.0000],
        [ 0.3858,  0.6232,  1.0000],
        [ 0.6664,  1.0694,  1.0000],
        [-0.0096,  0.5217,  1.0000],
        [ 0.4950,  1.9198,  1.0000],
        [ 1.0538,  1.3820,  1.0000],
        [-0.2613,  0.8820,  1.0000],
        [ 0.3996,  1.8843,  1.0000],
        [ 1.1924,  0.0861,  1.0000],
        [ 0.4659,  1.7043,  1.0000],
        [ 1.2955,  1.5032,  1.0000],
        [ 0.6273,  1.6799,  1.0000],
        [ 1.6033,  0.1661,  1.0000],
        [ 1.1614,  0.6470,  1.0000],
        [ 1.0195,  0.3744,  1.0000],
        [ 1.3668,  1.4446,  1.0000],
        [ 0.5516,  0.7548,  1.0000],
        [ 1.3437,  1.2409,  1.0000],
        [ 0.6146,  0.9260,  1.0000],
        [ 0.8570,  1.3993,  1.0000],
        [ 0.5396,  0.5329,  1.0000],
        [ 1.1257,  1.1977,  1.0000],
        [ 1.1677,  2.0080,  1.0000],
        [ 1.7434,  0.4813,  1.0000],
        [ 1.7205,  0.7583,  1.0000],
        [ 0.8614,  0.5443,  1.0000],
        [ 1.5042,  1.4127,  1.0000],
        [ 1.3134,  1.0174,  1.0000],
        [ 0.6180,  0.6978,  1.0000],
        [ 1.9709,  0.7133,  1.0000],
        [ 0.7136,  1.6948,  1.0000],
        [ 0.1170,  1.1652,  1.0000]])
y: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])</code></pre>
</div>
</div>
<div id="cell-7" class="cell" data-execution_count="59">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pyplot <span class="im">as</span> plt</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>plt.style.use(<span class="st">'seaborn-v0_8-whitegrid'</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_classification_data(X, y, ax):</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> X.shape[<span class="dv">1</span>] <span class="op">==</span> <span class="dv">3</span>, <span class="st">"This function only works for data created with p_dims == 2"</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    targets <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">1</span>]</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    markers <span class="op">=</span> [<span class="st">"o"</span> , <span class="st">","</span>]</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>):</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>        ix <span class="op">=</span> y <span class="op">==</span> targets[i]</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>        ax.scatter(X[ix,<span class="dv">0</span>], X[ix,<span class="dv">1</span>], s <span class="op">=</span> <span class="dv">20</span>,  c <span class="op">=</span> <span class="dv">2</span><span class="op">*</span>y[ix]<span class="op">-</span><span class="dv">1</span>, facecolors <span class="op">=</span> <span class="st">"none"</span>, edgecolors <span class="op">=</span> <span class="st">"darkgrey"</span>, cmap <span class="op">=</span> <span class="st">"BrBG"</span>, vmin <span class="op">=</span> <span class="op">-</span><span class="dv">2</span>, vmax <span class="op">=</span> <span class="dv">2</span>, alpha <span class="op">=</span> <span class="fl">0.5</span>, marker <span class="op">=</span> markers[i])</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    ax.<span class="bu">set</span>(xlabel <span class="op">=</span> <span class="vs">r"$x_1$"</span>, ylabel <span class="op">=</span> <span class="vs">r"$x_2$"</span>)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>, figsize <span class="op">=</span> (<span class="dv">4</span>, <span class="dv">4</span>))</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>plot_classification_data(X, y, ax)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-4-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="experiments" class="level1">
<h1>Experiments</h1>
<p>Now that we have some a binary classification dataset, we can use it to perform various experiments to fully illstrate Newton’s Method opitimization.</p>
<section id="experiment-1-comparing-standard-graident-descent-and-newtons-method" class="level2">
<h2 class="anchored" data-anchor-id="experiment-1-comparing-standard-graident-descent-and-newtons-method">Experiment 1: Comparing Standard Graident Descent and Newton’s Method</h2>
<p>Now that we have a binary classification dataset, we can declare two Logistic Regression models, one that will use the standard gradient opitimzer and one that will use Newton’s Method optimization.</p>
</section>
</section>
<section id="palmers-penguins-dataset-for-experiements" class="level1">
<h1>Palmers Penguins Dataset for Experiements</h1>
<div id="cell-11" class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>train <span class="op">=</span> pd.read_csv(<span class="st">"breast-cancer.csv"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="224">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">id</th>
<th data-quarto-table-cell-role="th">diagnosis</th>
<th data-quarto-table-cell-role="th">radius_mean</th>
<th data-quarto-table-cell-role="th">texture_mean</th>
<th data-quarto-table-cell-role="th">perimeter_mean</th>
<th data-quarto-table-cell-role="th">area_mean</th>
<th data-quarto-table-cell-role="th">smoothness_mean</th>
<th data-quarto-table-cell-role="th">compactness_mean</th>
<th data-quarto-table-cell-role="th">concavity_mean</th>
<th data-quarto-table-cell-role="th">concave points_mean</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">radius_worst</th>
<th data-quarto-table-cell-role="th">texture_worst</th>
<th data-quarto-table-cell-role="th">perimeter_worst</th>
<th data-quarto-table-cell-role="th">area_worst</th>
<th data-quarto-table-cell-role="th">smoothness_worst</th>
<th data-quarto-table-cell-role="th">compactness_worst</th>
<th data-quarto-table-cell-role="th">concavity_worst</th>
<th data-quarto-table-cell-role="th">concave points_worst</th>
<th data-quarto-table-cell-role="th">symmetry_worst</th>
<th data-quarto-table-cell-role="th">fractal_dimension_worst</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>842302</td>
<td>M</td>
<td>17.99</td>
<td>10.38</td>
<td>122.80</td>
<td>1001.0</td>
<td>0.11840</td>
<td>0.27760</td>
<td>0.3001</td>
<td>0.14710</td>
<td>...</td>
<td>25.38</td>
<td>17.33</td>
<td>184.60</td>
<td>2019.0</td>
<td>0.1622</td>
<td>0.6656</td>
<td>0.7119</td>
<td>0.2654</td>
<td>0.4601</td>
<td>0.11890</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>842517</td>
<td>M</td>
<td>20.57</td>
<td>17.77</td>
<td>132.90</td>
<td>1326.0</td>
<td>0.08474</td>
<td>0.07864</td>
<td>0.0869</td>
<td>0.07017</td>
<td>...</td>
<td>24.99</td>
<td>23.41</td>
<td>158.80</td>
<td>1956.0</td>
<td>0.1238</td>
<td>0.1866</td>
<td>0.2416</td>
<td>0.1860</td>
<td>0.2750</td>
<td>0.08902</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>84300903</td>
<td>M</td>
<td>19.69</td>
<td>21.25</td>
<td>130.00</td>
<td>1203.0</td>
<td>0.10960</td>
<td>0.15990</td>
<td>0.1974</td>
<td>0.12790</td>
<td>...</td>
<td>23.57</td>
<td>25.53</td>
<td>152.50</td>
<td>1709.0</td>
<td>0.1444</td>
<td>0.4245</td>
<td>0.4504</td>
<td>0.2430</td>
<td>0.3613</td>
<td>0.08758</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>84348301</td>
<td>M</td>
<td>11.42</td>
<td>20.38</td>
<td>77.58</td>
<td>386.1</td>
<td>0.14250</td>
<td>0.28390</td>
<td>0.2414</td>
<td>0.10520</td>
<td>...</td>
<td>14.91</td>
<td>26.50</td>
<td>98.87</td>
<td>567.7</td>
<td>0.2098</td>
<td>0.8663</td>
<td>0.6869</td>
<td>0.2575</td>
<td>0.6638</td>
<td>0.17300</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>84358402</td>
<td>M</td>
<td>20.29</td>
<td>14.34</td>
<td>135.10</td>
<td>1297.0</td>
<td>0.10030</td>
<td>0.13280</td>
<td>0.1980</td>
<td>0.10430</td>
<td>...</td>
<td>22.54</td>
<td>16.67</td>
<td>152.20</td>
<td>1575.0</td>
<td>0.1374</td>
<td>0.2050</td>
<td>0.4000</td>
<td>0.1625</td>
<td>0.2364</td>
<td>0.07678</td>
</tr>
</tbody>
</table>

<p>5 rows × 32 columns</p>
</div>
</div>
</div>
</section>
<section id="data-preprocessing" class="level1">
<h1>Data Preprocessing</h1>
<div id="cell-13" class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># from sklearn.model_selection import train_test_split</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> prepare_data(df):</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> df.dropna()</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> np.where(df[<span class="st">'diagnosis'</span>] <span class="op">==</span> <span class="st">"M"</span>, <span class="va">True</span>, <span class="va">False</span>)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> df.drop([<span class="st">'diagnosis'</span>], axis <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> df.drop([<span class="st">'id'</span>], axis <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>    scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>    X_scaled <span class="op">=</span> scaler.fit_transform(df)</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> X_scaled, y</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> prepare_data(train)</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.from_numpy(X.astype(np.float32))</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.from_numpy(y).<span class="bu">float</span>()</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.cat([X, torch.ones(X.shape[<span class="dv">0</span>], <span class="dv">1</span>)], dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a><span class="co"># X_train, X_test, y_train, y_test = train_test_split(</span></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a><span class="co">#      X, y, test_size=0.20, random_state=42)</span></span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a><span class="co"># X_train, X_validate, y_train, y_validate = train_test_split(</span></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a><span class="co">#     X_train, y_train, test_size=0.20, random_state=42)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-14" class="cell" data-execution_count="240">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Logistic Regression model with gradient descent optimizer</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>LR_GD <span class="op">=</span> LogisticRegression()</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>opt_GD <span class="op">=</span> GradientDescentOptimizer(LR_GD)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co">#Logistic Regression model with Newton's Method optimizer </span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>LR_NM <span class="op">=</span> LogisticRegression()</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>opt_NM <span class="op">=</span> NewtonOptimizer(LR_NM)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>num_iterations <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(num_iterations):</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>    opt_GD.step(X, y, <span class="fl">0.1</span>, <span class="dv">0</span>, <span class="va">False</span>, <span class="dv">0</span>)</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>    opt_NM.step(X, y, <span class="dv">1</span>)</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Gradient Descent Logistic Regression Loss: </span><span class="sc">{</span>LR_GD<span class="sc">.</span>loss(X,y)<span class="sc">}</span><span class="ch">\n</span><span class="ss">Newton's Method Logistic Regression Loss: </span><span class="sc">{</span>LR_NM<span class="sc">.</span>loss(X,y)<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Gradient Descent Logistic Regression Loss: 0.05876803398132324
Newton's Method Logistic Regression Loss: 0.08070827275514603
</code></pre>
</div>
</div>
</section>
<section id="results" class="level1">
<h1>Results</h1>
<p>We can see that when giving the standard gradient descent optimizer a learning rate of <code>0.1</code> and the Newton’s Method optimizer a learning rate of <code>1</code>, they produce a similar loss in the same amount of iterations.</p>
<section id="experiment-2-faster-convergence-using-newtons-method" class="level2">
<h2 class="anchored" data-anchor-id="experiment-2-faster-convergence-using-newtons-method">Experiment 2: Faster Convergence Using Newton’s Method</h2>
<p>Through this experiment I will demonstrate that Newton’s Method in certain circumstances can have a much faster convergence than Standard Gradient Descent optimizaiton. The circumstance shown below is when the data has low noise and low number of points and dimensions. In this case, Newton’s Method is able to converge faster than standard gradient descent.</p>
<div id="cell-17" class="cell" data-execution_count="248">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>LR_GD <span class="op">=</span> LogisticRegression()</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>opt_GD <span class="op">=</span> GradientDescentOptimizer(LR_GD)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co">#Logistic Regression model with Newton's Method optimizer </span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>LR_NM <span class="op">=</span> LogisticRegression()</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>opt_NM <span class="op">=</span> NewtonOptimizer(LR_NM)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Track loss over iterations</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>losses_gd <span class="op">=</span> []</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>losses_nm <span class="op">=</span> []</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Training loop</span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>n_steps <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n_steps):</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Gradient Descent</span></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>    opt_GD.step(X, y, <span class="fl">0.1</span>, <span class="dv">0</span>, <span class="va">False</span>, <span class="dv">0</span>)</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>    loss_gd <span class="op">=</span> LR_GD.loss(X, y).item()</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>    losses_gd.append(loss_gd)</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Newton's Method</span></span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>    opt_NM.step(X, y, alpha<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>    loss_nm <span class="op">=</span> LR_NM.loss(X, y).item()</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>    losses_nm.append(loss_nm)</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot convergence</span></span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>plt.plot(losses_gd, label<span class="op">=</span><span class="st">"Gradient Descent"</span>, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>plt.plot(losses_nm, label<span class="op">=</span><span class="st">"Newton's Method"</span>, marker<span class="op">=</span><span class="st">'x'</span>)</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Iteration"</span>)</span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Empirical Risk (Loss)"</span>)</span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Convergence Comparison: GD vs Newton"</span>)</span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-8-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="results-1" class="level1">
<h1>Results</h1>
<p>As demonsrated by the graph, in 100 iterations optimization with Newton’s Method reaches near zero loss, while the loss using standard gradient descent for optimization is around <code>0.25</code>.</p>
<section id="experiment-3-newtons-method-fails-to-converge-when-learing-rate-is-large" class="level2">
<h2 class="anchored" data-anchor-id="experiment-3-newtons-method-fails-to-converge-when-learing-rate-is-large">Experiment 3: Newton’s Method Fails to Converge When Learing Rate is Large</h2>
<p>Now, I will demonstrate how a large learning rate can cause Newton’s Method to fail to converge at all.</p>
<div id="cell-20" class="cell" data-execution_count="247">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># X, y = generate_classification_data(noise = 0.01, p_dims=2, n_points=2000)</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>LR_NM <span class="op">=</span> LogisticRegression()</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>opt_NM <span class="op">=</span> NewtonOptimizer(LR_NM)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Track loss over iterations</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>losses_nm <span class="op">=</span> []</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Training loop</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>n_steps <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n_steps):</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Newton's Method</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>    opt_NM.step(X, y, alpha<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>    loss_nm <span class="op">=</span> LR_NM.loss(X, y).item()</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>    losses_nm.append(loss_nm)</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot convergence</span></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>plt.plot(losses_nm, label<span class="op">=</span><span class="st">"Newton's Method"</span>, marker<span class="op">=</span><span class="st">'x'</span>)</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Iteration"</span>)</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Empirical Risk (Loss)"</span>)</span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Newton Convergence"</span>)</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-9-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="adam-optimization" class="level1">
<h1>Adam Optimization</h1>
<div id="cell-22" class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>LR_Adam <span class="op">=</span> LogisticRegression()</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>opt_Adam <span class="op">=</span> AdamOptimizer(LR_Adam)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>num_iterations <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(num_iterations):</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Using the same dataset X and y as with newtons method</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    opt_Adam.step(X, y, <span class="fl">0.01</span>, <span class="fl">0.9</span>, <span class="fl">0.999</span>, <span class="fl">1e-8</span>, <span class="dv">10</span>)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Gradient Descent Logistic Regression Loss: </span><span class="sc">{</span>LR_Adam<span class="sc">.</span>loss(X,y)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Gradient Descent Logistic Regression Loss: 0.20271477103233337</code></pre>
</div>
</div>
</section>
<section id="comparing-adam-optimzation-and-standard-minibatch-gradient-descent" class="level1">
<h1>Comparing Adam Optimzation and Standard Minibatch Gradient Descent</h1>
<div id="cell-24" class="cell" data-execution_count="184">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>num_iterations <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>step_size <span class="op">=</span> [<span class="fl">0.0001</span>, <span class="fl">0.001</span>, <span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="dv">1</span>]</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>minibatch_GD_loss <span class="op">=</span> []</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>adam_OPT_loss <span class="op">=</span> []</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> step <span class="kw">in</span> step_size: </span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>    LR_GD <span class="op">=</span> LogisticRegression()</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>    opt_GD <span class="op">=</span> GradientDescentOptimizer(LR_GD)</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>    LR_Adam <span class="op">=</span> LogisticRegression()</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>    opt_Adam <span class="op">=</span> AdamOptimizer(LR_Adam)</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(num_iterations):</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Using the same dataset X and y as with newtons method</span></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>        opt_Adam.step(X, y, step, <span class="fl">0.9</span>, <span class="fl">0.999</span>, <span class="fl">1e-8</span>, <span class="dv">10</span>)</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>        opt_GD.step(X, y, step, <span class="fl">0.9</span>, <span class="va">True</span>, <span class="dv">10</span>)</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>    adam_OPT_loss.append(LR_Adam.loss(X, y).item())</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>    minibatch_GD_loss.append(LR_GD.loss(X, y).item())</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Make some type of table</span></span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a><span class="co">#first convert to series</span></span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Minibatch GD Loss"</span>: minibatch_GD_loss,</span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Adam Optimizer Loss"</span>: adam_OPT_loss</span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>}, index<span class="op">=</span>step_size)</span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>        Minibatch GD Loss  Adam Optimizer Loss
0.0001           1.537306             1.534232
0.0010           1.546394             1.091133
0.0100           0.872059             0.018603
0.1000           0.008254             0.001868
1.0000           0.000414             0.152991</code></pre>
</div>
</div>
</section>
<section id="results-2" class="level1">
<h1>Results</h1>
<p>On average with the same batch size of 10, using the adam opitmizer converges faster than standard minibatch gradient descent when both optimizers have matching alpha values.</p>
</section>
<section id="comparing-adam-and-newtons-method-optimization" class="level1">
<h1>Comparing Adam and Newton’s Method Optimization</h1>
<div id="cell-27" class="cell" data-execution_count="185">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> generate_classification_data(noise <span class="op">=</span> <span class="fl">0.8</span>)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>LR_Adam <span class="op">=</span> LogisticRegression()</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>opt_Adam <span class="op">=</span> AdamOptimizer(LR_Adam)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>LR_NM <span class="op">=</span> LogisticRegression()</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>opt_NM <span class="op">=</span> NewtonOptimizer(LR_NM)</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>LOSS_THRESHOLD <span class="op">=</span> <span class="fl">0.2</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>MAX_ITER <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>start_adam <span class="op">=</span> time.time()</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(MAX_ITER):</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>    opt_Adam.step(X, y, step, <span class="fl">0.9</span>, <span class="fl">0.999</span>, <span class="fl">1e-8</span>, <span class="dv">10</span>)</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> LR_Adam.loss(X, y).item()</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> loss <span class="op">&lt;</span> LOSS_THRESHOLD:</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>end_adam <span class="op">=</span> time.time()</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>adam_time <span class="op">=</span> end_adam <span class="op">-</span> start_adam</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>start_newton <span class="op">=</span> time.time()</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(MAX_ITER):</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>    opt_NM.step(X, y, <span class="fl">0.9</span>)</span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> LR_NM.loss(X, y).item()</span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> loss <span class="op">&lt;</span> LOSS_THRESHOLD:</span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>end_newton <span class="op">=</span> time.time()</span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>newton_time <span class="op">=</span> end_newton <span class="op">-</span> start_newton</span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Newton's Method Optimization converge time: </span><span class="sc">{</span>newton_time<span class="sc">}</span><span class="ch">\n</span><span class="ss">Adam Optimization converge time: </span><span class="sc">{</span>adam_time<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Newton's Method Optimization converge time: 0.043290138244628906
Adam Optimization converge time: 0.06393694877624512</code></pre>
</div>
</div>
</section>
<section id="results-3" class="level1">
<h1>Results</h1>
<p>Seems like Newton’s Method converges faster than Adam Optimization on this dataset.</p>
</section>
<section id="results-4" class="level1">
<h1>Results</h1>
<p>Here, we demonstrate that Logistic Regression using either Newton’s Method or Gradient Descent optimization can converge to a similar value given enough iterations and a small enough learning rate <code>α</code>.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>